{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06dd17da-2081-42cc-9b19-16f295b18ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcc852b-0292-45ae-95ed-7731063dec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acrossmap': None, 'admin': False, 'answers': {'across': ['HERB', 'CROW', 'HAVE', 'AMOR', 'HOPE', 'TOLET', 'LIBERATED', 'INLET', 'ELEVATOR', 'LOIRE', 'RYDER', 'ASTERN', 'EASTER', 'IVAN', 'ASP', 'FLEECE', 'NANA', 'DELAYED', 'UNAGING', 'IRAN', 'GUARDS', 'NAY', 'TEST', 'ACCESS', 'TENREC', 'ETAPE', 'STELE', 'REASONER', 'TOROS', 'TELLSOVER', 'ADEPT', 'ETAL', 'LIVE', 'RODE', 'DENY', 'SLED'], 'down': ['HALER', 'EMILY', 'ROBED', 'BREVE', 'CHAT', 'ROTO', 'OPERATE', 'WED', 'HONORING', 'ALLINVAIN', 'VEER', 'ETTE', 'TILE', 'RAREFY', 'SECURE', 'TRENDS', 'ALEGAR', 'SEDUCE', 'ANNA', 'NAGY', 'ADIT', 'SERE', 'PLASTERED', 'ANTELOPE', 'ASSESS', 'ACCRETE', 'NEST', 'TOOLS', 'ANVIL', 'PEEVE', 'ERRED', 'STAR', 'TODO', 'ELAN', 'ALLY', 'TED']}, 'author': 'Martha J. DeWitt', 'autowrap': None, 'bbars': None, 'circles': None, 'clues': {'across': ['1. Fennel or sweet cicely', '5. Eat ___ (suffer humiliation)', '9. \"To ___ and to Hold,\" Johnston novel', '13. Cupid', '14. Lange from Conn.', '15. House sign', '16. What NOW wants women to be', '18. Ocean arm', '19. Follower of grain or freight', \"20. Orleans's river\", '21. ___ Cup (golf prize)', \"22. Boatman's backward\", '25. March 26, 1978', '28. Pavlov', '31. Relative of a daboia', '34. Defraud', '35. Pram pusher', '36. Put off', '38. Describing eternal youth', \"40. Pahlavi's country\", '41. Cerberus et al.', '43. Aye neutralizer', '44. Put to the ___', '45. Passageway', '46. Madagascar mammal', '48. Storehouse of a sort', '53. Inscribed pillar', '55. Newscaster', '58. Bulls, in Barcelona', '59. Repeats a report', '60. Proficient', '61. Abbr. often used on deeds', '62. Kind of wire', '63. Harassed', '64. Abjure', '65. Pung or monoski'], 'down': [\"1. Item in a Czech's wallet\", '2. Girl in \"Our Town\"', '3. Togate', '4. Longest modern musical note', '5. Converse idly', '6. Turning on an axis: Comb. form', '7. Work or run', '8. Join', '9. Paying homage to', '10. \"Mock on, mock on, \\'tis ___\": Blake', '11. Change course', '12. Feminine suffix', '15. Mah-jongg piece', '17. Make thin or porous', '23. Safe', '24. Drifts', '26. Vinegar made from a liquor', '27. Lure', '29. Soprano Moffo', '30. Former Hungarian prime minister', '31. Mine entrance', '32. Sapless', '33. Three sheets to the wind', '37. Player on the range', '39. Rate or evaluate', '42. Adhere or combine', '47. Aerie, e.g.', '49. Puppets', '50. Famous \"Chorus\"', '51. Irk', '52. Dropped a fly', '53. \"___ Wars\"', '54. Foofaraw', '56. Dash', '57. Confederate', '59. Kennedy or Heath']}, 'code': None, 'copyright': '1978, The New York Times', 'date': '2/2/1978', 'dow': 'Thursday', 'downmap': None, 'editor': 'Eugene T. Maleska', 'grid': ['H', 'E', 'R', 'B', '.', 'C', 'R', 'O', 'W', '.', '.', 'H', 'A', 'V', 'E', 'A', 'M', 'O', 'R', '.', 'H', 'O', 'P', 'E', '.', 'T', 'O', 'L', 'E', 'T', 'L', 'I', 'B', 'E', 'R', 'A', 'T', 'E', 'D', '.', 'I', 'N', 'L', 'E', 'T', 'E', 'L', 'E', 'V', 'A', 'T', 'O', 'R', '.', '.', 'L', 'O', 'I', 'R', 'E', 'R', 'Y', 'D', 'E', 'R', '.', '.', 'A', 'S', 'T', 'E', 'R', 'N', '.', '.', '.', '.', '.', '.', 'E', 'A', 'S', 'T', 'E', 'R', '.', 'I', 'V', 'A', 'N', 'A', 'S', 'P', '.', 'F', 'L', 'E', 'E', 'C', 'E', '.', 'N', 'A', 'N', 'A', 'D', 'E', 'L', 'A', 'Y', 'E', 'D', '.', 'U', 'N', 'A', 'G', 'I', 'N', 'G', 'I', 'R', 'A', 'N', '.', 'G', 'U', 'A', 'R', 'D', 'S', '.', 'N', 'A', 'Y', 'T', 'E', 'S', 'T', '.', 'A', 'C', 'C', 'E', 'S', 'S', '.', '.', '.', '.', '.', '.', 'T', 'E', 'N', 'R', 'E', 'C', '.', '.', 'E', 'T', 'A', 'P', 'E', 'S', 'T', 'E', 'L', 'E', '.', '.', 'R', 'E', 'A', 'S', 'O', 'N', 'E', 'R', 'T', 'O', 'R', 'O', 'S', '.', 'T', 'E', 'L', 'L', 'S', 'O', 'V', 'E', 'R', 'A', 'D', 'E', 'P', 'T', '.', 'E', 'T', 'A', 'L', '.', 'L', 'I', 'V', 'E', 'R', 'O', 'D', 'E', '.', '.', 'D', 'E', 'N', 'Y', '.', 'S', 'L', 'E', 'D'], 'gridnums': [1, 2, 3, 4, 0, 5, 6, 7, 8, 0, 0, 9, 10, 11, 12, 13, 0, 0, 0, 0, 14, 0, 0, 0, 0, 15, 0, 0, 0, 0, 16, 0, 0, 0, 17, 0, 0, 0, 0, 0, 18, 0, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 21, 0, 0, 0, 0, 0, 0, 22, 23, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 26, 27, 0, 0, 0, 0, 28, 0, 29, 30, 31, 32, 33, 0, 34, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, 36, 0, 0, 37, 0, 0, 0, 0, 38, 0, 39, 0, 0, 0, 0, 40, 0, 0, 0, 0, 41, 0, 42, 0, 0, 0, 0, 43, 0, 0, 44, 0, 0, 0, 0, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 0, 47, 0, 0, 0, 0, 0, 48, 49, 50, 51, 52, 53, 54, 0, 0, 0, 0, 0, 55, 56, 57, 0, 0, 0, 0, 0, 58, 0, 0, 0, 0, 0, 59, 0, 0, 0, 0, 0, 0, 0, 0, 60, 0, 0, 0, 0, 0, 61, 0, 0, 0, 0, 62, 0, 0, 0, 63, 0, 0, 0, 0, 0, 64, 0, 0, 0, 0, 65, 0, 0, 0], 'hold': None, 'id': None, 'id2': None, 'interpretcolors': None, 'jnotes': None, 'key': None, 'mini': None, 'notepad': None, 'publisher': 'The New York Times', 'rbars': None, 'shadecircles': None, 'size': {'cols': 15, 'rows': 15}, 'title': 'NY TIMES, THU, FEB 02, 1978', 'track': None, 'type': None}\n"
     ]
    }
   ],
   "source": [
    "# filepath on Ishan's Mac -> change if someone else uses this\n",
    "file_path = \"/Users/ishan//Desktop/cs224n/02.json\"\n",
    "\n",
    "if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        print(data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "else:\n",
    "    print(\"File does not exist or is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8692011c-b6c9-4352-bb5c-0f06f75692e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizing Berkeley's crosswords struct with a few additional functions for what we need\n",
    "\n",
    "class Crossword:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.across_clues = {}\n",
    "        self.down_clues = {}\n",
    "        self.clue_to_positions = {}\n",
    "        self.solution_dict = {}\n",
    "        self.clue_grid = None\n",
    "        self.neighbors = {}\n",
    "\n",
    "    def initialize_solution_map(self):\n",
    "        # first do across\n",
    "        clues = self.data['clues']['across']\n",
    "        answers = self.data['answers']['across']\n",
    "        for i, clue in enumerate(clues):\n",
    "            period_idx = clue.find('.')\n",
    "            num, rest = clue[:period_idx], clue[period_idx+1:]\n",
    "            self.solution_dict[f\"{num}A\"] = answers[i]\n",
    "\n",
    "        # now do down\n",
    "        clues = self.data['clues']['down']\n",
    "        answers = self.data['answers']['down']\n",
    "        for i, clue in enumerate(clues):\n",
    "            period_idx = clue.find('.')\n",
    "            num, rest = clue[:period_idx], clue[period_idx+1:]\n",
    "            self.solution_dict[f\"{num}D\"] = answers[i]\n",
    "\n",
    "\n",
    "    def initialize_clues(self):\n",
    "        \"\"\"\n",
    "        Take in dictionary representing crossword and fill in dictionaries that hole clue codes (i.e. 1a/3d/18a/etc) \n",
    "        and map to corresppnding clue.\n",
    "        \"\"\"\n",
    "        for clue in self.data['clues']['across']:\n",
    "            period_idx = clue.find('.')\n",
    "            num, rest = clue[:period_idx], clue[period_idx+1:]\n",
    "            self.across_clues[f\"{num}A\"] = rest\n",
    "\n",
    "        for clue in self.data['clues']['down']:\n",
    "            period_idx = clue.find('.')\n",
    "            num, rest = clue[:period_idx], clue[period_idx+1:]\n",
    "            self.down_clues[f\"{num}D\"] = rest\n",
    "\n",
    "    def initialize_clue_positions_mapping(self):\n",
    "        \"\"\"\n",
    "        Take clue dictionary from self.across_clues and self.down_clues in the form {'1A': clue, etc ...}, \n",
    "        build a dictionary that maps clue ID to coordinates in grid\n",
    "        \"\"\"\n",
    "        # first do across\n",
    "        for clue in self.across_clues:\n",
    "            num = int(clue[:-1])\n",
    "            answer_len = len(self.solution_dict[clue])\n",
    "            start = list(self.data['gridnums']).index(num)\n",
    "            row, col = start // 15, start % 15 \n",
    "            # this is across, so now that we have a start index, add corresponding coord to map\n",
    "            coords = []\n",
    "            for i in range(answer_len):\n",
    "                coords.append((row, col + i))\n",
    "            self.clue_to_positions[clue] = coords\n",
    "\n",
    "        # now do down\n",
    "        for clue in self.down_clues:\n",
    "            num = int(clue[:-1])\n",
    "            answer_len = len(self.solution_dict[clue])\n",
    "            start = list(self.data['gridnums']).index(num)\n",
    "            row, col = start // 15, start % 15 # convert from 1D array index to grid coord\n",
    "            # this is across, so now that we have a start index, add corresponding coord to map\n",
    "            coords = []\n",
    "            for i in range(answer_len):\n",
    "                coords.append((row + i, col))\n",
    "            self.clue_to_positions[clue] = coords\n",
    "    \n",
    "\n",
    "    def initialize_clue_grid(self):\n",
    "        \"\"\"\n",
    "        Represent a grid in the form of each cell being filled into to show what clue it corresponds to.\n",
    "        For example:\n",
    "        grid = [[('1A, 1D'), ('1A, 2D')],\n",
    "                [('2A, 1D'), ('2A, 2D')]]\n",
    "        \"\"\"\n",
    "\n",
    "        grid = [\n",
    "            [[None, None] for _ in range(15)] for _ in range(15)\n",
    "        ]\n",
    "        \n",
    "        for clue in self.across_clues.keys():\n",
    "            coords = self.clue_to_positions[clue]\n",
    "            for (x, y) in coords:\n",
    "                grid[x][y][0] = clue\n",
    "\n",
    "        for clue in self.down_clues.keys():\n",
    "            coords = self.clue_to_positions[clue]\n",
    "            for (x, y) in coords:\n",
    "                grid[x][y][1] = clue\n",
    "\n",
    "        self.clue_grid = grid\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        self.initialize_clues()\n",
    "        self.initialize_solution_map()\n",
    "        self.initialize_clue_positions_mapping()\n",
    "        self.initialize_clue_grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17706699-0b69-43e9-9da3-e73f410b35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = Crossword(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646dc94b-b37c-4554-bc9c-6855d413bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e41a9ea-aa29-4063-8536-5add3c33f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = trial.solution_dict\n",
    "down_answers = {}\n",
    "across_answers = {}\n",
    "for item in solutions:\n",
    "    if item[-1] == 'D':\n",
    "        down_answers[item] = solutions[item]\n",
    "    else:\n",
    "        across_answers[item] = solutions[item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a76ca1b-4caa-4f34-8bdb-04dfe3eccff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial.across_clues\n",
    "down_clues = trial.down_clues\n",
    "across_clues = trial.across_clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59839bbd-74f1-4a94-b285-7ea27a7f42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Fennel or sweet cicely, 4,', ' Eat ___ (suffer humiliation), 4,', ' \"To ___ and to Hold,\" Johnston novel, 4,', ' Cupid, 4,', ' Lange from Conn., 4,', ' House sign, 5,', ' What NOW wants women to be, 9,', ' Ocean arm, 5,', ' Follower of grain or freight, 8,', \" Orleans's river, 5,\", ' ___ Cup (golf prize), 5,', \" Boatman's backward, 6,\", ' March 26, 1978, 6,', ' Pavlov, 4,', ' Relative of a daboia, 3,', ' Defraud, 6,', ' Pram pusher, 4,', ' Put off, 7,', ' Describing eternal youth, 7,', \" Pahlavi's country, 4,\", ' Cerberus et al., 6,', ' Aye neutralizer, 3,', ' Put to the ___, 4,', ' Passageway, 6,', ' Madagascar mammal, 6,', ' Storehouse of a sort, 5,', ' Inscribed pillar, 5,', ' Newscaster, 8,', ' Bulls, in Barcelona, 5,', ' Repeats a report, 9,', ' Proficient, 5,', ' Abbr. often used on deeds, 4,', ' Kind of wire, 4,', ' Harassed, 4,', ' Abjure, 4,', ' Pung or monoski, 4,', \" Item in a Czech's wallet, 5,\", ' Girl in \"Our Town\", 5,', ' Togate, 5,', ' Longest modern musical note, 5,', ' Converse idly, 4,', ' Turning on an axis: Comb. form, 4,', ' Work or run, 7,', ' Join, 3,', ' Paying homage to, 8,', ' \"Mock on, mock on, \\'tis ___\": Blake, 9,', ' Change course, 4,', ' Feminine suffix, 4,', ' Mah-jongg piece, 4,', ' Make thin or porous, 6,', ' Safe, 6,', ' Drifts, 6,', ' Vinegar made from a liquor, 6,', ' Lure, 6,', ' Soprano Moffo, 4,', ' Former Hungarian prime minister, 4,', ' Mine entrance, 4,', ' Sapless, 4,', ' Three sheets to the wind, 9,', ' Player on the range, 8,', ' Rate or evaluate, 6,', ' Adhere or combine, 7,', ' Aerie, e.g., 4,', ' Puppets, 5,', ' Famous \"Chorus\", 5,', ' Irk, 5,', ' Dropped a fly, 5,', ' \"___ Wars\", 4,', ' Foofaraw, 4,', ' Dash, 4,', ' Confederate, 4,', ' Kennedy or Heath, 3,']\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "\n",
    "for item in across_clues:\n",
    "    clue = across_clues[item]\n",
    "    ans = across_answers[item]\n",
    "    length = len(ans)\n",
    "    input_text = str(clue) + ',' + ' ' + str(length) + ','\n",
    "    inputs.append(input_text)\n",
    "\n",
    "for item in down_clues:\n",
    "    clue = down_clues[item]\n",
    "    ans = down_answers[item]\n",
    "    length = len(ans)\n",
    "    input_text = str(clue) + ',' + ' ' + str(length) + ','\n",
    "    inputs.append(input_text)\n",
    "\n",
    "\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6d68c7e-3d4c-4418-9961-8937f3cb6180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1A', '5A', '9A', '13A', '14A', '15A', '16A', '18A', '19A', '20A', '21A', '22A', '25A', '28A', '31A', '34A', '35A', '36A', '38A', '40A', '41A', '43A', '44A', '45A', '46A', '48A', '53A', '55A', '58A', '59A', '60A', '61A', '62A', '63A', '64A', '65A', '1D', '2D', '3D', '4D', '5D', '6D', '7D', '8D', '9D', '10D', '11D', '12D', '15D', '17D', '23D', '24D', '26D', '27D', '29D', '30D', '31D', '32D', '33D', '37D', '39D', '42D', '47D', '49D', '50D', '51D', '52D', '53D', '54D', '56D', '57D', '59D']\n"
     ]
    }
   ],
   "source": [
    "across_keys = list(trial.across_clues.keys())\n",
    "down_keys = list(trial.down_clues.keys())\n",
    "all_keys = across_keys + down_keys\n",
    "print(all_keys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4698319f-c9ae-4499-975f-1450ddc98500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Users/ishan/miniconda3/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/ishan/miniconda3/lib/python3.10/site-packages (from openai==0.28) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /Users/ishan/miniconda3/lib/python3.10/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/ishan/miniconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "{'1A': ['HERB'], '5A': ['CROW'], '9A': ['HAVE'], '13A': ['AMOR'], '14A': ['ANNE', 'REPW', 'HANK', 'INES', 'VERA'], '15A': ['LEOIV', 'SCORP'], '16A': ['ASSERTIVE'], '18A': ['YEMEN', 'FJORD'], '19A': ['CARTELOT', 'CARTELLI'], '20A': ['TEDES', 'FROST', 'PEEDE', 'TEJAS', 'WABAS'], '21A': ['RYDER'], '22A': ['ASTERN'], '25A': ['EASTER'], '28A': ['IVAN'], '31A': ['ASP'], '34A': ['SHORTC', 'FLIMFL', 'BILKED'], '35A': ['MUMS', 'YANK'], '36A': ['DEFERRE', 'DEFERRED'], '38A': ['AGELESS'], '40A': ['IRAN'], '41A': ['HOUNDS', 'HELLDO'], '43A': ['NAY', 'NAK'], '44A': ['TEST', 'SWORD', 'ROUE'], '45A': ['THROAT'], '46A': ['LEMURS'], '48A': ['ABBEY', 'CROCK', 'CELLAR', 'FATCA'], '53A': ['STELE'], '55A': ['ANCHORMAN', 'ANCHORER'], '58A': ['TOROS'], '59A': ['CONFIRMS', 'ECHOESIT'], '60A': ['ADEPT', 'ABLES'], '61A': ['TENR', 'ETAL', 'FIPS', 'LISA'], '62A': ['BARB', 'LOOP'], '63A': ['RIDOF', 'RODE', 'RANAT'], '64A': ['FORGO', 'FOGO'], '65A': ['ECHO', 'ITEM', 'SLED', 'TOYS', 'ALPINE'], '1D': ['KRONE', 'KORUN'], '2D': ['EMILY'], '3D': ['ROBED'], '4D': ['SEMIB', 'BREVE'], '5D': ['CHAT'], '6D': ['GURI', 'GYRO', 'GYRA', 'TROI'], '7D': ['OPERATE'], '8D': ['TIE'], '9D': ['ADHERING', 'INHONOR', 'REVERENT', 'ADULATING'], '10D': ['SUNKENFAC', 'ENGLISH', 'SACREDFIRE', 'NAYOURS'], '11D': ['VEER'], '12D': ['ETTE'], '15D': ['DORA', 'TILE', 'BAMM'], '17D': ['RAREFY'], '23D': ['SECURE', 'INSURE', 'UNHURT', 'INHAND'], '24D': ['ROAMS', 'TRENDS', 'WANDER', 'LEEWAS'], '26D': ['TARRER', 'TARRAS'], '27D': ['ENTICE', 'ATTRACT'], '29D': ['ANNA'], '30D': ['NAGY'], '31D': ['ADIT'], '32D': ['WANJ', 'SERE', 'WANF'], '33D': ['OSSIFIED', 'STINKEROO', 'STINKING'], '37D': ['DRIVERER', 'GOLFBALL', 'SANDWEDGE', 'PRACTICE'], '39D': ['SIZING', 'ASSIGN'], '42D': ['COHERER', 'UNIFIES', 'COHERE'], '47D': ['NEST'], '49D': ['TOOLS'], '50D': ['ATTIC', 'HEARS', 'MAMEA', 'ODETO', 'EWEIN'], '51D': ['VEXAT', 'FAZES', 'EATAT'], '52D': ['ERRED'], '53D': ['COLA', 'STARS', 'ROHR', 'STAR'], '54D': ['ADO'], '56D': ['ELAN'], '57D': ['ALLY'], '59D': ['TEO', 'TED']}\n"
     ]
    }
   ],
   "source": [
    "# work on unique completions\n",
    "\n",
    "import openai \n",
    "\n",
    "!pip install openai==0.28\n",
    "\n",
    "openai.api_key = 'sk-proj-8oLvnNGJLnlgW4SQOoHwT3BlbkFJ8c24SWE59CoO4sTxlDC7'\n",
    "\n",
    "with open('/Users/ishan/Desktop/cs224n/fine_tuned_model_name.txt', 'r') as f:\n",
    "    fine_tuned_model = f.read().strip()\n",
    "\n",
    "def generate_unique_completions(prompt, model, num_completions=5, max_tokens=50):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        n=num_completions,  \n",
    "        stop=None,\n",
    "        temperature=0.9,  \n",
    "        top_p=0.9  \n",
    "    )\n",
    "    completions = set()\n",
    "    for choice in response['choices']:\n",
    "        completions.add(choice['message']['content'].strip())\n",
    "        if len(completions) >= num_completions:\n",
    "            break\n",
    "    \n",
    "    return list(completions)[:num_completions]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "candidates = {key: [] for key in all_keys}\n",
    "\n",
    "\n",
    "for idx, prompt in enumerate(inputs):\n",
    "    completions = generate_unique_completions(prompt, fine_tuned_model, num_completions=5)\n",
    "    for completion in completions:\n",
    "        candidates[all_keys[idx]].append(completion)\n",
    "\n",
    "print(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9edd2a1-390a-43bc-bedf-282c5f5008a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishan/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# get bi-encoder\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dec29a3-0260-4c28-8080-e58f6ceabf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishan/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bi_encoder = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5f7a1d8-a1d0-43d4-9dd9-e33b71e14caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1A': ['HERB'], '5A': ['CROW'], '9A': ['HAVE'], '13A': ['AMOR'], '14A': ['ANNE', 'REPW', 'HANK', 'INES', 'VERA'], '15A': ['LEOIV', 'SCORP'], '16A': ['ASSERTIVE'], '18A': ['YEMEN', 'FJORD'], '19A': ['CARTELOT', 'CARTELLI'], '20A': ['TEDES', 'FROST', 'PEEDE', 'TEJAS', 'WABAS'], '21A': ['RYDER'], '22A': ['ASTERN'], '25A': ['EASTER'], '28A': ['IVAN'], '31A': ['ASP'], '34A': ['SHORTC', 'FLIMFL', 'BILKED'], '35A': ['MUMS', 'YANK'], '36A': ['DEFERRE', 'DEFERRED'], '38A': ['AGELESS'], '40A': ['IRAN'], '41A': ['HOUNDS', 'HELLDO'], '43A': ['NAY', 'NAK'], '44A': ['TEST', 'SWORD', 'ROUE'], '45A': ['THROAT'], '46A': ['LEMURS'], '48A': ['ABBEY', 'CROCK', 'CELLAR', 'FATCA'], '53A': ['STELE'], '55A': ['ANCHORMAN', 'ANCHORER'], '58A': ['TOROS'], '59A': ['CONFIRMS', 'ECHOESIT'], '60A': ['ADEPT', 'ABLES'], '61A': ['TENR', 'ETAL', 'FIPS', 'LISA'], '62A': ['BARB', 'LOOP'], '63A': ['RIDOF', 'RODE', 'RANAT'], '64A': ['FORGO', 'FOGO'], '65A': ['ECHO', 'ITEM', 'SLED', 'TOYS', 'ALPINE'], '1D': ['KRONE', 'KORUN'], '2D': ['EMILY'], '3D': ['ROBED'], '4D': ['SEMIB', 'BREVE'], '5D': ['CHAT'], '6D': ['GURI', 'GYRO', 'GYRA', 'TROI'], '7D': ['OPERATE'], '8D': ['TIE'], '9D': ['ADHERING', 'INHONOR', 'REVERENT', 'ADULATING'], '10D': ['SUNKENFAC', 'ENGLISH', 'SACREDFIRE', 'NAYOURS'], '11D': ['VEER'], '12D': ['ETTE'], '15D': ['DORA', 'TILE', 'BAMM'], '17D': ['RAREFY'], '23D': ['SECURE', 'INSURE', 'UNHURT', 'INHAND'], '24D': ['ROAMS', 'TRENDS', 'WANDER', 'LEEWAS'], '26D': ['TARRER', 'TARRAS'], '27D': ['ENTICE', 'ATTRACT'], '29D': ['ANNA'], '30D': ['NAGY'], '31D': ['ADIT'], '32D': ['WANJ', 'SERE', 'WANF'], '33D': ['OSSIFIED', 'STINKEROO', 'STINKING'], '37D': ['DRIVERER', 'GOLFBALL', 'SANDWEDGE', 'PRACTICE'], '39D': ['SIZING', 'ASSIGN'], '42D': ['COHERER', 'UNIFIES', 'COHERE'], '47D': ['NEST'], '49D': ['TOOLS'], '50D': ['ATTIC', 'HEARS', 'MAMEA', 'ODETO', 'EWEIN'], '51D': ['VEXAT', 'FAZES', 'EATAT'], '52D': ['ERRED'], '53D': ['COLA', 'STARS', 'ROHR', 'STAR'], '54D': ['ADO'], '56D': ['ELAN'], '57D': ['ALLY'], '59D': ['TEO', 'TED']}\n"
     ]
    }
   ],
   "source": [
    "print(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75b80f3f-8af7-4c9f-ac97-283ef0643152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: HERB, Probability: 1.0000\n",
      "Answer: CROW, Probability: 1.0000\n",
      "Answer: HAVE, Probability: 1.0000\n",
      "Answer: AMOR, Probability: 1.0000\n",
      "Answer: MELA, Probability: 0.0000\n",
      "Answer: EELI, Probability: 0.0000\n",
      "Answer: TOMS, Probability: 0.1278\n",
      "Answer: ALAN, Probability: 0.8721\n",
      "{'1A': None, '5A': None, '9A': None, '13A': None, '14A': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# I downloaded sentence_transformers and then this should work\n",
    "\n",
    "def biencoder(clue, answers):\n",
    "\n",
    "    def encode_texts(bi_encoder, texts):\n",
    "        return bi_encoder.encode(texts)\n",
    "    \n",
    "    def calculate_similarity(clue_embedding, answer_embeddings):\n",
    "        return util.dot_score(clue_embedding, answer_embeddings)[0].cpu().numpy()\n",
    "    \n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    clue_embedding = encode_texts(bi_encoder, [clue])[0]\n",
    "    answer_embeddings = encode_texts(bi_encoder, answers)\n",
    "    \n",
    "    similarity_scores = calculate_similarity(clue_embedding, answer_embeddings)\n",
    "    probabilities = softmax(similarity_scores)\n",
    "    \n",
    "    answer_probabilities = list(zip(answers, probabilities))\n",
    "    \n",
    "    \n",
    "    for answer, probability in answer_probabilities:\n",
    "        print(f\"Answer: {answer}, Probability: {probability:.4f}\")\n",
    "\n",
    "confidence_ratings = {}\n",
    "\n",
    "# Iterate over the first 5 items in all_clues_actual and call biencoder with each clue and its candidates\n",
    "for i, (key, clue) in enumerate(all_clues_actual.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    candidate_answers = candidates.get(key, [])\n",
    "    if candidate_answers: \n",
    "        confidence_ratings[key] = biencoder(clue, candidate_answers)\n",
    "\n",
    "# pass this rating thing to bi-encoder\n",
    "print(confidence_ratings)\n",
    "   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba54c419-3c2e-4559-98f0-fe5575fb1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1A': ' Fennel or sweet cicely', '5A': ' Eat ___ (suffer humiliation)', '9A': ' \"To ___ and to Hold,\" Johnston novel', '13A': ' Cupid', '14A': ' Lange from Conn.', '15A': ' House sign', '16A': ' What NOW wants women to be', '18A': ' Ocean arm', '19A': ' Follower of grain or freight', '20A': \" Orleans's river\", '21A': ' ___ Cup (golf prize)', '22A': \" Boatman's backward\", '25A': ' March 26, 1978', '28A': ' Pavlov', '31A': ' Relative of a daboia', '34A': ' Defraud', '35A': ' Pram pusher', '36A': ' Put off', '38A': ' Describing eternal youth', '40A': \" Pahlavi's country\", '41A': ' Cerberus et al.', '43A': ' Aye neutralizer', '44A': ' Put to the ___', '45A': ' Passageway', '46A': ' Madagascar mammal', '48A': ' Storehouse of a sort', '53A': ' Inscribed pillar', '55A': ' Newscaster', '58A': ' Bulls, in Barcelona', '59A': ' Repeats a report', '60A': ' Proficient', '61A': ' Abbr. often used on deeds', '62A': ' Kind of wire', '63A': ' Harassed', '64A': ' Abjure', '65A': ' Pung or monoski', '1D': \" Item in a Czech's wallet\", '2D': ' Girl in \"Our Town\"', '3D': ' Togate', '4D': ' Longest modern musical note', '5D': ' Converse idly', '6D': ' Turning on an axis: Comb. form', '7D': ' Work or run', '8D': ' Join', '9D': ' Paying homage to', '10D': ' \"Mock on, mock on, \\'tis ___\": Blake', '11D': ' Change course', '12D': ' Feminine suffix', '15D': ' Mah-jongg piece', '17D': ' Make thin or porous', '23D': ' Safe', '24D': ' Drifts', '26D': ' Vinegar made from a liquor', '27D': ' Lure', '29D': ' Soprano Moffo', '30D': ' Former Hungarian prime minister', '31D': ' Mine entrance', '32D': ' Sapless', '33D': ' Three sheets to the wind', '37D': ' Player on the range', '39D': ' Rate or evaluate', '42D': ' Adhere or combine', '47D': ' Aerie, e.g.', '49D': ' Puppets', '50D': ' Famous \"Chorus\"', '51D': ' Irk', '52D': ' Dropped a fly', '53D': ' \"___ Wars\"', '54D': ' Foofaraw', '56D': ' Dash', '57D': ' Confederate', '59D': ' Kennedy or Heath'}\n"
     ]
    }
   ],
   "source": [
    "all_clues = []\n",
    "for (key, val) in trial.across_clues.items():\n",
    "    all_clues.append(val)\n",
    "\n",
    "for (key, val) in trial.down_clues.items():\n",
    "    all_clues.append(val)\n",
    "\n",
    "all_clues_actual = {}\n",
    "for i in range(len(all_clues)):\n",
    "    all_clues_actual[all_keys[i]] = all_clues[i]\n",
    "\n",
    "print(all_clues_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8ea689-8d6f-4299-8cef-f9c8590598dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2c5c45d-3322-48d1-94a6-42e231329b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1A': {'HERB': 1.0}, '5A': {'CROW': 1.0}, '9A': {'HAVE': 1.0}, '13A': {'AMOR': 1.0}, '14A': {'ANNE': 0.48943096, 'REPW': 0.059694137, 'HANK': 0.09849533, 'INES': 0.0008574594, 'VERA': 0.35152215}, '15A': {'LEOIV': 0.36919644, 'SCORP': 0.6308035}, '16A': {'ASSERTIVE': 1.0}, '18A': {'YEMEN': 1.954321e-06, 'FJORD': 0.9999981}, '19A': {'CARTELOT': 0.7712528, 'CARTELLI': 0.22874717}, '20A': {'TEDES': 0.0004267744, 'FROST': 1.9153504e-07, 'PEEDE': 0.0014748239, 'TEJAS': 0.8140384, 'WABAS': 0.18405981}, '21A': {'RYDER': 1.0}, '22A': {'ASTERN': 1.0}, '25A': {'EASTER': 1.0}, '28A': {'IVAN': 1.0}, '31A': {'ASP': 1.0}, '34A': {'SHORTC': 2.4104588e-06, 'FLIMFL': 0.26476982, 'BILKED': 0.7352277}, '35A': {'MUMS': 0.00059641973, 'YANK': 0.9994036}, '36A': {'DEFERRE': 0.16892241, 'DEFERRED': 0.8310776}, '38A': {'AGELESS': 1.0}, '40A': {'IRAN': 1.0}, '41A': {'HOUNDS': 0.9979923, 'HELLDO': 0.002007778}, '43A': {'NAY': 0.9999647, 'NAK': 3.529474e-05}, '44A': {'TEST': 0.034744713, 'SWORD': 0.94785655, 'ROUE': 0.017398752}, '45A': {'THROAT': 1.0}, '46A': {'LEMURS': 1.0}, '48A': {'ABBEY': 0.003923113, 'CROCK': 1.1162147e-06, 'CELLAR': 0.9960757, 'FATCA': 2.106102e-09}, '53A': {'STELE': 1.0}, '55A': {'ANCHORMAN': 0.6617696, 'ANCHORER': 0.3382304}, '58A': {'TOROS': 1.0}, '59A': {'CONFIRMS': 0.99769443, 'ECHOESIT': 0.002305507}, '60A': {'ADEPT': 0.9999999, 'ABLES': 1.2884513e-07}, '61A': {'TENR': 1.8534146e-07, 'ETAL': 0.9999831, 'FIPS': 9.5490265e-08, 'LISA': 1.6549242e-05}, '62A': {'BARB': 0.80731857, 'LOOP': 0.19268142}, '63A': {'RIDOF': 0.01999001, 'RODE': 0.9113471, 'RANAT': 0.06866287}, '64A': {'FORGO': 0.43983856, 'FOGO': 0.5601614}, '65A': {'ECHO': 0.96072996, 'ITEM': 0.010291923, 'SLED': 0.0001024185, 'TOYS': 0.028872503, 'ALPINE': 3.2191667e-06}, '1D': {'KRONE': 0.9995859, 'KORUN': 0.00041410152}, '2D': {'EMILY': 1.0}, '3D': {'ROBED': 1.0}, '4D': {'SEMIB': 0.008313812, 'BREVE': 0.99168617}, '5D': {'CHAT': 1.0}, '6D': {'GURI': 6.910436e-05, 'GYRO': 0.96099883, 'GYRA': 0.029287782, 'TROI': 0.009644187}, '7D': {'OPERATE': 1.0}, '8D': {'TIE': 1.0}, '9D': {'ADHERING': 0.043806355, 'INHONOR': 1.6982018e-09, 'REVERENT': 0.9561425, 'ADULATING': 5.1216502e-05}, '10D': {'SUNKENFAC': 1.403324e-08, 'ENGLISH': 0.0051267697, 'SACREDFIRE': 0.00019034186, 'NAYOURS': 0.99468285}, '11D': {'VEER': 1.0}, '12D': {'ETTE': 1.0}, '15D': {'DORA': 2.4697115e-07, 'TILE': 2.023799e-08, 'BAMM': 0.99999976}, '17D': {'RAREFY': 1.0}, '23D': {'SECURE': 0.9999994, 'INSURE': 3.253539e-09, 'UNHURT': 6.1378574e-07, 'INHAND': 4.4677574e-15}, '24D': {'ROAMS': 0.7918783, 'TRENDS': 0.03930569, 'WANDER': 0.16881588, 'LEEWAS': 1.5680496e-07}, '26D': {'TARRER': 0.97702575, 'TARRAS': 0.022974331}, '27D': {'ENTICE': 5.5892644e-07, 'ATTRACT': 0.9999994}, '29D': {'ANNA': 1.0}, '30D': {'NAGY': 1.0}, '31D': {'ADIT': 1.0}, '32D': {'WANJ': 0.04174244, 'SERE': 0.001409884, 'WANF': 0.95684767}, '33D': {'OSSIFIED': 0.9447731, 'STINKEROO': 0.04586763, 'STINKING': 0.009359303}, '37D': {'DRIVERER': 2.084424e-09, 'GOLFBALL': 1.0, 'SANDWEDGE': 3.0313568e-12, 'PRACTICE': 2.659915e-08}, '39D': {'SIZING': 0.014589433, 'ASSIGN': 0.9854106}, '42D': {'COHERER': 6.374451e-05, 'UNIFIES': 0.99934596, 'COHERE': 0.0005902591}, '47D': {'NEST': 1.0}, '49D': {'TOOLS': 1.0}, '50D': {'ATTIC': 1.5462372e-07, 'HEARS': 0.23820694, 'MAMEA': 0.7149968, 'ODETO': 0.046795104, 'EWEIN': 9.4223265e-07}, '51D': {'VEXAT': 0.29342127, 'FAZES': 0.655986, 'EATAT': 0.050592747}, '52D': {'ERRED': 1.0}, '53D': {'COLA': 4.0712823e-08, 'STARS': 0.25395894, 'ROHR': 0.19743423, 'STAR': 0.54860675}, '54D': {'ADO': 1.0}, '56D': {'ELAN': 1.0}, '57D': {'ALLY': 1.0}, '59D': {'TEO': 2.5728708e-08, 'TED': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "bi_encoder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def biencoder(clue, answers):\n",
    "    def encode_texts(bi_encoder, texts):\n",
    "        return bi_encoder.encode(texts)\n",
    "    \n",
    "    def calculate_similarity(clue_embedding, answer_embeddings):\n",
    "        return util.dot_score(clue_embedding, answer_embeddings)[0].cpu().numpy()\n",
    "    \n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    clue_embedding = encode_texts(bi_encoder, [clue])[0]\n",
    "    answer_embeddings = encode_texts(bi_encoder, answers)\n",
    "    \n",
    "    similarity_scores = calculate_similarity(clue_embedding, answer_embeddings)\n",
    "    probabilities = softmax(similarity_scores)\n",
    "    \n",
    "    answer_probabilities = {answer: prob for answer, prob in zip(answers, probabilities)}\n",
    "    \n",
    "    return answer_probabilities\n",
    "\n",
    "\n",
    "confidence_ratings = {}\n",
    "\n",
    "\n",
    "for i, (key, clue) in enumerate(all_clues_actual.items()):\n",
    "    candidate_answers = candidates.get(key, [])\n",
    "    if candidate_answers:  \n",
    "        confidence_ratings[key] = biencoder(clue, candidate_answers)\n",
    "\n",
    "print(confidence_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef75eae-c793-4b1e-ba46-d03e8f9d1a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
